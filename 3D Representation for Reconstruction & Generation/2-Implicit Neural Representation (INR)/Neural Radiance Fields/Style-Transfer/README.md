# <p align=center>`Style Transfer` </p>





## Introduction

3D style transfer aims to transform the appearance of a 3D scene so that its rendering from different viewpoints match the style of a desired image. Utilizing a high-quality 3D geometric representation (neural radiance field),  this task can be 







## Literature

[Stylizing 3D Scene via Implicit Representation and HyperNetwork](https://arxiv.org/abs/2105.13016)  
*Pei-Ze Chiang, Meng-Shiun Tsai, Hung-Yu Tseng, Wei-sheng Lai, Wei-Chen Chiu*  
**[`WACV 2022`] (`NYCU`)** [[code](https://github.com/ztex08010518/Stylizing-3D-Scene)]

[StylizedNeRF: Consistent 3D Scene Stylization as Stylized NeRF via 2D-3D Mutual Learning](https://arxiv.org/abs/2205.12183)  
*Yi-Hua Huang, Yue He, Yu-Jie Yuan, Yu-Kun Lai, Lin Gao*  
**[`CVPR 2022`] (`CAS`)** [[code](https://github.com/IGLICT/StylizedNeRF)]

[ARF: Artistic Radiance Fields](https://arxiv.org/abs/2206.06360)  
*Kai Zhang, Nick Kolkin, Sai Bi, Fujun Luan, Zexiang Xu, Eli Shechtman, Noah Snavely*  
**[`ECCV 2022`] (`Cornell`)** [[code](https://github.com/Kai-46/ARF-svox2)]

[SNeRF: Stylized Neural Implicit Representations for 3D Scenes](https://arxiv.org/abs/2207.02363)  
*Thu Nguyen-Phuoc, Feng Liu, Lei Xiao*  
**[`SIGGRAPH 2022`] (`Meta`)** 





### Comparision



